# SimpleWikiScraper

A python program to scrape information from wikipedia articles such as hyperlink and image count. Relies on BeautifulSoup and Urllib2. Written to test out the libraries and try some basic scraping of webpages.

## Getting Started

Simply run in your prefered python IDE.

### Prerequisites

Requires Python 3.x.x

## Built With

* [BeautifulSoup](https://www.crummy.com/software/BeautifulSoup/) - Filtering and extracting of webpage content
* [Urllib2](https://docs.python.org/2/library/urllib2.html) - Gathering webpage data and getting html to be processed
* [Python](https://www.python.org/) - IDE and language

## Authors

* **FHoughton** - *Initial work* - [Fhoughton](https://github.com/Fhoughton)

See also the list of [contributors](https://github.com/Fhoughton/SimpleWikiScraper/contributors) who participated in this project.

## License

This project is licensed under the GNU General Public License - see the [LICENSE.md](LICENSE) file for details

## Acknowledgments

* Based off an article by [DigitalOcean](www.digitalocean.com)
